<html>
<head>
<meta charset="UTF-8">
<link rel='stylesheet' href='style1.css'/>
<title>Social AI</title>
</head></p>

<p><body>
<div class="container" ></p>

<h1>Developing Social AI</h1>

<p><div style="overflow: hidden;"><div class="quote"><em>
What I cannot create, I do not understand<br>  Richard Feynman</em></div></div><p></p></p>
<p><div style="overflow: hidden;"><div class="quote"><em> 
Instead of trying to produce a programme to simulate the adult mind,<br> why not rather try to produce one which simulates the child's?</em><br> Alan Turing </div></div><p></p></p>

<div>
<p>
This project dual work of understanding how people can manage social relationhips at the same time that implement them into Artificial Intelligence.
</p><p>
Recent developments in Machine Learning and collective effort can lead us a long way into this. 
While most use huge neural networks with implicit knowledge, our social AI will build models of the world, for explanation, imagination, planning,  After all, <em>consciousness itself happens when are manipulating world models.</em>
</p>We propose:
 <ul>
 <li class='big-li'><a href = 'https://arxiv.org/abs/1610.03585'> Grounding on a environment </a> (<a href='#env'>see below</a>) that exercises social abilities (in a abstract way; We will ignore audio-visual and motor abilities for now.)</li>
 
 <li class='big-li'><details><summary>Implement "infant-like knowledge representations"  (vs waiting the Gradient descent to work)</summary>
<blockquote>
  <p><em>Finally, we recognize that some researchers still hold out hope that if only they can just get big enough training datasets, sufficiently rich tasks, and enough computing power -- far beyond what has been tried out so far -- then deep learning methods might be sufficient to learn representations equivalent to what evolution and learning provides humans with. We can sympathize with that hope and believe it deserves further exploration, although we are not sure it is a realistic one. We understand in principle how evolution could build a brain with the cognitive ingredients we discuss here.<b> Stochastic hill-climbing is slow -- it may require massively parallel exploration, over millions of years with innumerable dead-ends -- but it can build complex structures with complex functions if we are willing to wait long enough. In contrast, trying to build these representations from scratch using backpropagation, deep Q-learning or any stochastic gradient-descent weight update rule in a fixed network architecture may be unfeasible regardless of how much training data are available. To build these representations from scratch might require exploring fundamental structural variations in the network's architecture, which gradient-based learning in weight space is not prepared to do.</b> Although deep learning researchers do explore many such architectural variations, and have been devising increasingly clever and powerful ones recently, it is the researchers who are driving and directing this process. Exploration and creative innovation in the space of network architectures have not yet been made algorithmic. Perhaps they could, using genetic programming methods or other structure-search algorithms . We think this would be a fascinating and promising direction to explore, but we may have to acquire more patience than machine learning researchers typically express with their algorithms: the dynamics of structure-search may look much more like the slow random hill-climbing of evolution than the smooth, methodical progress of stochastic gradient-descent. An alternative strategy is to build in appropriate infant-like knowledge representations and core ingredients as the starting point for our learning-based AI systems, or to build learning systems with strong inductive biases that guide them in this direction.</em>
<a href="https://arxiv.org/abs/1604.00289">Building Machines That Learn and Think Like People</a></p>
</blockquote></details></li>
 
 <li class='big-li'> Nodes representing basic features: agents, words, times, events, numbers, energy, etc. Probabilistic activations and sqeuences implement more abstract concepts.</li>
 
 <li class='big-li'> Start with a basic language containing <a href='Roadmap.html#InitLang'> interrogatives, conditionals, imperatives, causality, actors, imaginary sequences of events</a>. Social / moral concepts will be later defined atop these representations. </li>
 
 
 <li class='big-li'>Reinforcement Learinig with self-play for comprehensive/automatic exploration of new social scenarios
    (<a href='https://en.wikipedia.org/wiki/AlphaZero'>Alphazero</a>, <a href='References.html#DealDeal'>Negotiatition</a>)</li>
     
<li class='big-li'><a href='Roadmap.html#PredNet'>Generative networks for past/ future/ capabilities/ event generation, trained at each time step with actual events.</a></li>

<li class='big-li'>  <a href='References.html#CompReason'> Multi-hop reasoning </a>for complex mental operations such as question answering and planning. </li>

 <li class='big-li'>  Interactive training: <a href='References.html#Annabel'>users evaluate </a> if the action is correct in a scenario
        <a href='References.html#Dungeon'>and suggest better options .</a>  
        <em>(TODO: save retraining effort when the architecture is updated)</em>
        </li>
        
 <li class='big-li'>   Processing of events and (real or imaginary) temporal sequences <em>(work in progress)</em> </li>
 
  <li class='big-li'> <a href='Roadmap.html#FPS'>Social planning </a> [<a href='References.html#SocialPlan'>1</a>,<a href='References.html#LogicTom1'>2</a> , <a href='References.html#LogicToM3'>3</a>] with <a href='References.html#Indspeech'>Sophisticated language use</a>,   
  using <a href='References.html#BayesToM'>bayesian</a><a href='References.html#PragmaticLang'> reasoning</a> to understand other minds 
  and <a href='References.html#LogRuleInd'>rule extraction</a> for interpretability</li>

<li class='big-li'>
<details><summary>Coding skills directly when alternatives are not efficient</summary>
<blockquote>
  <p><em>This raises the question of how humans might learn even more abstract tasks,and Bengio (2013b) studies the hypothesis that the use of language and the evolution of culture could have helped humans reduce that difficulty(...) The basic idea is that humans (and current learning algorithms) are limited to “local descent” optimization methods, that make small changes in the parameter values with the effect of reducing the expected loss in average. This is clearly prone to the presence of local minima, while a more global search (in the spirit of both genetic and cultural evolu tion) could potentially reduce this difficulty. One hypothesis is that more abstract learning tasks involve more challenging optimization difficulties, which would make such global optimization algorithms necessary if we want computers to learn such abstractions from scratch. Another option, following the idea of curriculum learning (Bengio et al., 2009), is to provide guidance ourselves to learning machines (as exemplified in the toy example of Gulcehre and Bengio (2013)), by “teaching them” gradually more complex concepts to help them understand the world around us (<b>keeping in mind that we also have to do that for humans and that it takes 20 years to complete</b>).</em> 
<a href="https://arxiv.org/abs/1203.2990">Evolving Culture vs Local Minima, Y Bengio
</a>
</p>
</blockquote>
</details>
</li>
</ul>
</div>
<hr>


<details style='font-size:100%'><summary>More info about the present status</summary>

<p>The present code iteration used hard-coded naive heuristics of language use. The interactions use a json-like expression instead of a natural language. 
</p><p>
The agents self-played for some time  so they could learn models of the enviromnent, themselves and other agents. And also what to speak to influence each other.

The results were inconclusive.<a href= 'https://openai.com/blog/ai-and-compute' > Teams with access to thousands of Petaflop/s-days can try to do better. </a>
</p><p>
Now is the hard work of implementing reasoning skills and teaching lessons whenever gradient descent is too slow.  
</p>
</details>
<a href='#' style='font-size:150%'>Try it</a><br>
<a href='Roadmap.html' style='font-size:150%' >Roadmap </a><br>

<a href='#' style='font-size:150%'>Code</a><br>
<a href='etc/index-etc.html' style='font-size:100%'>Other stuff</a><br>
<a href='etc/squares/d.html' style='font-size:100%'>Original Squares Project</a>
<br><hr><br>


<p>Socially believable agents are important milestones for, among other things:</p>

<ul>
<li>Personal assistants,responsible chatbots</li>
<li>Healthcare Robots</li>
<li>

<details><summary>Videogame Non-Player Characters (NPCs)</summary>

<blockquote>
  <em><p>A deeper system would provide a world filled with dynamic Machiavellian Plotters.(..)</p>
<p>If NPCs possessed social reasoning, then open-ended action games can be about power dyanmics. They may support strategies in which the player forges and betrays lasting relationships with NPCs instead of just shooting. Think of an interactive version of the Wire, House of cards or the Sopranos. These TV shows are about weaving and unweaving of complex interpersonal relationships as a means to na end. NPCs with innocuous beginnings could become regular companions, or grow into mortal enemies.(…)</p><p>
One possible future for the open world game may be na experience that combnins the Sims, which features lifelong ambition arcs, with something like PromWeek,the  fascinating project that simulate social interactions between students.</p></em> 
  <a href="https://www.theguardian.com/technology/2016/oct/12/video-game-characters-emotional-ai-developers">Video games where people matter? The strange future of emotional AI</a></p>
</blockquote></details>


</li>
<li>research on (Evolutionary) Psychology</li>
<li> Consciousness, qualia and the <em>Value Alignment problem</em> <a href="Consc.html">(More details)</a> </li>
</ul>

<a name='env'></a>
<h1>Environment and Evolutionary Psychology</h1>

<p><div style="overflow: hidden;"><div class="quote"><em>
It's a gene-eat-gene world
 </em></div></div><p></p></p>

<p><blockquote>
The human goal-system, which includes survival, social status, and morality, along with many others, is a mix of  adaptations to conditions in the human ancestral environment 
 <br><b>BUT</b><br>
Even though the human mind evolved to serve evolutionary goals of reproductive success, humans do not share the goals of the evolutionary processes which created them  </em>
(Tooby and Cosmides 1992;  J. D. Greene 2002).
</blockquote></p>

<p>The environment used to explore the human psychology and how it evolved</p>

<p>Our environment will lead to interpersonal competiiton as a driver for interesting phenomena . The amount of food is limited and thea gents have to compete for mates, feed theis children and relate to peers and kin They can forage food, give or hit (remove) energy to/from other agents, and mate leading to offsring. Agents may have inheritable fitness <a href="References.html#AttMate">AttMate</a>  and psychological characteristics. </p>

<p>While we could evolve these algorithmes, to lessen computational costs the instints  drives(feed, mate, help kin and offspring, make friends etc), and emotions(happiness, sadness, fear, anger, surprise etc) will be to some extent hardcoded.</p>



<p>The default environment is a bare-bones representation of aspects from the environment where our ancestors lived and where our  behavior evolved: small groups, foraging, sharing food. In principle we would not implement matarial obejcts; </p>

<p>More concretely, it is a hypothetical land with enough food to support some 200 agents. Each agent has a gender, age and level of energy, that inreases by eating and decreases with age and sickness. If the energy reaches 0 the agent dies.</p>

<p><div style="overflow: hidden;"><div class="quote"><em>
Perfection is attained not when no more can be added, but when no more can be removed<br></em>
 Antoine de Saint Exupery
</div></div><p></p></p>

<p><img src="environment.png" alt="Environment" title=""  class='center'/></p>

<p>At each step the agents can take these actions:</p>

<ul>
<li>talk in private to a group of its choosing</li>
<li>give energy/food/money from others (or hit to remove energy)</li>
<li>mate </li>
</ul>

<p>There is a probability that private actions  of other agents will be discovered by an random agent, leading eventually to gossip.</p>



<h3>Relationships</h3>

<p><div style="overflow: hidden;"><div class="quote"><em> 
Hell are other people </em><br> Sartre
</div></div><p></p></p>

<p><div style="overflow: hidden;"><div class="quote"><em>
I against my brother.<br> I and my brother against my cousin.
<br> I, my brother and my cousin against the stranger</em><br> Bedouin proverb
</div></div><p></p></p>

<p><img src="relationships.png" alt="Environment" title=""  class='center' style='width:40%'/>
<span class='center' style='font-size:70%;text-align:center'><a href='References.html#AlgoSoc'> Algorithms of Social Life:</a> 
The author surveys the kinds of relationship <br>and their algorithmic, evolutionary and neural/hormonal contexts. </span> 
</p>


<p>The agents need to cooperate to forage the food and decide  how to share it. As the food is limited, competition arises between them.  They should decide how to allocate it between kin, mates and friends, and avoid or win conflicts. </p>



<h3>Coalitions</h3>

<p><!-- div style="overflow: hidden;"><div class="quote" -->
<blockquote>
<em>  Every human bears the whole stamp of the human condition. This includes evolved neural programs specialized for navigating the world of coalitions—teams, not groups. These programs enable us and induce us to form, maintain, join, support, recognize, defend, defect from, factionalize, exploit, resist, subordinate, distrust, dislike, oppose, and attack coalitions.</em>  <a href="https://www.edge.org/response-detail/27168"> John Tooby</a> 
</blockquote>
<!-- /div></div><p></p-->
</p>

<li><a name="CoalitionRep"
<p>The use of a large population > 100, allows to explore the <a href='References.html#Nperson'>psychology</a><a href='References.html#CoalitionRep'> of coalition-forming.</a></p>

<p>They reproduce sexually, transmiting genes that control their behavior ( or use the number of grandchildren as a proxy to fitness to calculate gradientes for updating a neural network). So acquiring mates, childcare and building relationhips become crucial.</p>

<h3>Values</h3>

<p>
<blockquote>
<em>  Much of human life´s meaning arguably depends on the enjoyment, for its own sake, of humor,love, game-playing, art,sex, dancing, social conversation, philosophy, literature, scientific discovery, sport, food and drink, friendship and parenting</em> 
</blockquote>
<a href='Roadmap.html#values'>Possible implementation</a>
</p>

<!-- p><div style="overflow: hidden;"><div class="quote"><em> 

</em></div></div><p></p></p -->






<h1>Release</h1>

<p>We intend to release the software in a open-source sandbox to generate and edit histories/narratives. 
The API will probably allow a timeline to go forward, rewind, saved, replayed with different random seed.
You may get;set the mind of agents using code or eventually natural language commands.
It would also be possible to use the neural world model to generate a narrative instead of simulating directly.
For example: "There was 10 people who" and the model completes the story, while the user may also edit.</p>

<p>Actaully applications of this technique will need customization and insertion of domain-specific knowledge and personalities.
(Where the <a href="http://en.wikipedia.org/wiki/Uncanny_Valley">uncanny valley</a> will arise if one asks stuff the agents are not prepared to answer - "Do you like ice-cream?" )</p>

<p>The interaction convincing if situated whitihn the boundaries of the agent's world. For an example, asking an agent about the relationship with his friends or what funny situtations it experienced. 
One may try mathematically or philosophically inclined agents.</p>

<h1>How can you help?</h1>

<ul>
<li>implement these featurs in the agent and in parallel to </li>
<li>build scenarios that test them, </li>
<li>advertise this site!</li>
</ul>

<p><we need you poster></p>


</body></html>
